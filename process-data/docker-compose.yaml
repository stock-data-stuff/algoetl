version: '3'

services:
  spark-master:
    image: bde2020/spark-master:3.2.0-hadoop3.2
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    volumes:
      - type: bind
        source: ./spark/scripts
        target: /scripts
      - type: bind
        source: ../feed-history
        target: /feed_history

  spark-worker-1:
    image: bde2020/spark-worker:3.2.0-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    volumes:
      - type: bind
        source: ../feed-history
        target: /feed_history

  spark-worker-2:
    image: bde2020/spark-worker:3.2.0-hadoop3.2
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    volumes:
      - type: bind
        source: ../feed-history
        target: /feed_history

  spark-history-server:
    image: bde2020/spark-history-server:3.2.0-hadoop3.2
    container_name: spark-history-server
    depends_on:
      - spark-master
    ports:
      - "18081:18081"

  postgresdb:
    image: "postgres"  # use latest official postgres version
    env_file:
      - ./postgresql/postgresql.env  # configure postgres
    volumes:
      - ./postgresql/postgres-data:/var/lib/postgresql/data/
      - ./postgresql/scripts:/shared/scripts:rw
    ports:
      - 5432:5432
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
