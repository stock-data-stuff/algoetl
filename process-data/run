#!/bin/bash

function show_usage()
{
    printf "Usage: $0 <command>\n"
    cat <<EOF
    -u|--up
    -d|--down
    -c|--clean-all
    -s|--status
    -p|--pyspark
    -t|--test-postgresql
    -P|--login-postgresql
    -S|--login-spark
    -h|--help
EOF
  exit 1
}

if [[ $# -lt 1 ]]; then
    show_usage $@
fi

function docker_login_postgresql()
{
    docker-compose exec postgresdb bash
}

function docker_login_spark()
{
    docker-compose exec spark-master bash
}

function docker_up()
{
    docker-compose up --detach
}

function docker_down()
{
    docker-compose down
}

function docker_clean_all()
{
    docker-compose rm -s -f
}

function docker_status()
{
    docker-compose ps -a
    docker-compose logs postgresdb | tail -10
}

function docker_run_pyspark()
{
    docker-compose exec -w /spark spark-master ./bin/pyspark --conf spark.sql.catalogImplementation=hive
}

function docker_run_initial_load()
{
    docker-compose exec -w /scripts spark-master ./initial-load
}

function test_postgresql()
{
    ./postgresql/scripts/test_postgresql
}

while [[ $# -gt 0 ]]; do
  key="$1"

  case $key in
    -S|--login-spark)
        shift
        docker_login_spark
        ;;
    -P|--login-postgresql)
        shift
        docker_login_postgresql
        ;;
    -u|--up)
        shift
        docker_up
        ;;
    -d|--down)
        shift
        docker_down
        ;;
    -c|--clean-all)
        shift
        docker_clean_all
        ;;
    -s|--status)
        shift
        docker_status
        ;;
    -p|--pyspark)
        shift
        docker_run_pyspark
        ;;
    -i|--initial-load)
        shift
        docker_run_initial_load
        ;;
    -t|--test-postgresql)
        shift
        test_postgresql
        ;;
    -h|--help)
        show_usage
      ;;
    *)    # unknown option
      POSITIONAL+=("$1") # save it in an array for later
      shift # past argument
      ;;
  esac
done

