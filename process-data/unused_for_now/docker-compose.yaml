version: '3'

services:
  spark-master:
    image: bde2020/spark-master:3.2.0-hadoop3.2
    container_name: spark-master
    ports:
      - "8080:8080"  # SPARK_MASTER_WEBUI_PORT: Web UI
      - "7077:7077"  # SPARK_MASTER_PORT: submit jobs and join cluster
    environment:
      - INIT_DAEMON_STEP=setup_spark
    volumes:
      - ./spark/scripts:/scripts
      - ../feed-history:/feed_history

  spark-worker-1:
    image: bde2020/spark-worker:3.2.0-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    volumes:
      - ../feed-history:/feed_history

  spark-worker-2:
    image: bde2020/spark-worker:3.2.0-hadoop3.2
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    volumes:
      - ../feed-history:/feed_history

  spark-history-server:
    image: bde2020/spark-history-server:3.2.0-hadoop3.2
    container_name: spark-history-server
    depends_on:
      - spark-master
    ports:
      - "18081:18081"

  # Use the latest Debian-based image
  # It's bigger, but lets us install common tools
  postgresdb:
    image: "postgres:bullseye"
    env_file:
      - ./postgresql/postgresql.env
    volumes:
      - ./postgresql/pg_data:/var/lib/postgresql/data/
      - ./postgresql/scripts:/scripts:rw
    ports:
      - 5432:5432
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
