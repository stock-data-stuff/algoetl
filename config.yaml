# This config file controls the pyalgofetcher program

# TODO: add support for writing to multiple destinations (in the same run)
# Places to write the data we fetch
output_destinations: "file"
#destinations: "file,postgresql"

output_config:
  file:
    # CSV and JSON are supported via https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html
    #format: "csv"
    format: json
    format_args:
      # CSV
      header: true # header line
      # JSON
      orient: "records" # or "table"
      # CSV and JSON
      compression: None # or "gz", "bz2", "xz", and, less preferred, "zip"
  #postgresql:

# List the feeds in this section
#
# Every feed is identified by a key (e.g. FED_Soma)
# Do not use a key (under "feeds:") of "ALL" since it is reserved to mean "load all feeds here"
#
# Each feed must have an API section
# It's helpful to group feeds here by API (for human readability)
feeds:
  # StockCharts data is scraped
  # https://support.stockcharts.com/doku.php?id=faqs:can_i_export_your_data_into_another_program_like_excel_or_metastock
  # It seems ok to just mimic what a person could do.
  # But, slow the program down to about human 'web-traversal' speed.
  # We don't want to be a burden on the site.
  vix:         # feeds[KEY] is used to name the directory and file with the data
    api: sc
    api_args:
      symbol: '$VIX'
      #symbol: 'VIX'    # 'symbol' is used to construct the URL to fetch the data
  # These work
  ibm:
    api: sc
    api_args:
      symbol: IBM
  aapl:
    api: sc
    api_args:
      symbol: AAPL

  # API docs: https://apps.newyorkfed.org/~/media/XML/Schemas/api_spec
  #
  # This feed/API is flaky... it fails randomly. Commenting it out for now
  # TODO: add metadata so that this can be skipped unless invoked specifically
  #
  #fed_soma:
  #  api: fed
  #  api_args:
  #    symbol: "FED_Soma"
  #    productCode: "30"
  #    query: "details"
  #    holdingTypes: "bills,notesbonds,frn,tips,cmbs,agency%20debts"
  #    format: "csv"
  #
  # TODO: Somehow deal with the fact that this API is fragile.
  # It always seems to succeed if a year of data is pulled, but often fails if fewer days are pulled
  # FAIL
  #  ./pyalgofetcher.py -f FED_Soma -s 1990-11-01 -e 1990-12-31 -d /tmp
  # SUCCEED
  # ./pyalgofetcher.py -f FED_Soma -s 1990-01-01 -e 1991-01-01 -d /tmp


  #VIX: # Seems to only have data from 2014-12-04 and 2018-01-31
  #  api: pdr
  #  api_args:
  #    symbol: "VIX"
  #    source: "yahoo"
  spy:
    api: pdr
    api_args:
      symbol: "SPY"
      source: "yahoo"

# TODO: consider driving the ETL from this
#
# etl:
#   schema:
#    api:
#      sc:
#      fed:
#      pdr:


# Do not put private information in this file!
# Copy this section into a file ./overrides.yaml and set the parameters there.
credentials:
  feed_api:
    whysper:
      username: username-override-me
      password: password-override-me
    sc:
      username: username-override-me
      password: password-override-me
  # The DB is local, but if we use a remote DB, put those credentials in the override.yaml file.
  database:
    db_type: postgresql
    postgresql_args:
      db_host: localhost
      db_port: 5432
      db_user: test
      db_password: test
      db_database_name: test  # Used in full/3-part table name
      # Schemas. # Used in full/3-part table name
      schema_stage: stg  # Temp space, for ingestion.
      schema_production: prd  # Long-term physical/historical table data. Optimize as needed.
      schema_report: rpt  # Static external (VIEW) interface to prod data and report tables.