# This config file controls the code that gets and processs data

output_destinations: "file"

output_config:
  file:
    format: json
    format_args:
      header: true # header line (for CSV)
      orient: "records" # or "table" (for JSON)
      compression: None # or "gz", "bz2", "xz", and, less preferred, "zip" (for CSV and JSON)

# List the feeds in this section
#
# Every feed is identified by a key (e.g. FED_Soma)
# Do not use a key (under "feeds:") of "ALL" since it is reserved to mean "load all feeds here"
#
# Each feed must have an API section
# It's helpful to group feeds here by API (for human readability)
feeds:
  # StockCharts data is scraped
  # https://support.stockcharts.com/doku.php?id=faqs:can_i_export_your_data_into_another_program_like_excel_or_metastock
  # It seems ok to just mimic what a person could do.
  # But, slow the program down to about human 'web-traversal' speed.
  # We don't want to be a burden on the site.
  vix:         # feeds[KEY] is used to name the directory and file with the data
    api: sc
    api_args:
      symbol: '$VIX'
      #symbol: 'VIX'    # 'symbol' is used to construct the URL to fetch the data
  # These work
  ibm:
    api: sc
    api_args:
      symbol: IBM
  aapl:
    api: sc
    api_args:
      symbol: AAPL

  # API docs: https://apps.newyorkfed.org/~/media/XML/Schemas/api_spec
  #
  # This feed/API is flaky... it fails randomly. Commenting it out for now
  # TODO: add metadata so that this can be skipped unless invoked specifically
  #
  #fed_soma:
  #  api: fed
  #  api_args:
  #    symbol: "FED_Soma"
  #    productCode: "30"
  #    query: "details"
  #    holdingTypes: "bills,notesbonds,frn,tips,cmbs,agency%20debts"
  #    format: "csv"
  #
  # TODO: Somehow deal with the fact that this API is fragile.
  # It always seems to succeed if a year of data is pulled, but often fails if fewer days are pulled
  # FAIL
  #  ./pyalgofetcher.py -f FED_Soma -s 1990-11-01 -e 1990-12-31 -d /tmp
  # SUCCEED
  # ./pyalgofetcher.py -f FED_Soma -s 1990-01-01 -e 1991-01-01 -d /tmp


  #VIX: # Seems to only have data from 2014-12-04 and 2018-01-31
  #  api: pdr
  #  api_args:
  #    symbol: "VIX"
  #    source: "yahoo"
  #
  #spy:  # AS OF 2022-01-16, this is not returning 'date' data.
  #  api: pdr
  #  api_args:
  #    symbol: "SPY"
  #    source: "yahoo"


# Do not put private information in this file!
# Copy this section into a file ./overrides.yaml and set the parameters there.
credentials:
  feed_api:
    whysper:
      username: username-override-me
      password: password-override-me
    sc:
      username: username-override-me
      password: password-override-me
  # The DB is local, but if we use a remote DB, put those credentials in the override.yaml file.
  database:
    # Database type (only postgresql is supported for now)
    db_type: postgresql
    # Postgresql connection info
    postgresql_args:
      db_host: localhost
      db_port: 5432
      db_user: test
      db_password: test
      db_database_name: test
    # TODO: move this to a different section. This is not secrent information
    # Schemas.
    schema_stage: stg  # Temp space, for ingestion.
    schema_production: prd  # Long-term physical/historical table data. Optimize as needed.
    schema_report: rpt  # Static external (VIEW) interface to prod data and report tables.
    # Table names
    prod_denormalized_feed_table: dn_feeds