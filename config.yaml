# This config file controls the pyalgofetcher program

# TODO: add support for writing to multiple destinations (in the same run)
# Places to write the data we fetch
output_destinations: "file"
#destinations: "file,postgresql"

output_config:
  file:
    # CSV and JSON are supported via https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html
    #format: "csv"
    format: json
    format_args:
      # CSV
      header: true # header line
      # JSON
      orient: "records" # or "table"
      # CSV and JSON
      compression: None # or "gz", "bz2", "xz", and, less preferred, "zip"
  #postgresql:

# List the feeds in this section
#
# Every feed is identified by a key (e.g. FED_Soma)
# Do not use a key (under "feeds:") of "ALL" since it is reserved to mean "load all feeds here"
#
# Each feed must have an API section
# It's helpful to group feeds here by API (for human readability)
feeds:
  # StockCharts data is scraped
  # https://support.stockcharts.com/doku.php?id=faqs:can_i_export_your_data_into_another_program_like_excel_or_metastock
  # It seems ok to just mimic what a person could do.
  # But, slow the program down to about human 'web-traversal' speed.
  # We don't want to be a burden on the site.
  VIX_from_sc:         # feeds[KEY] is used to name the directory and file with the data
    api: sc
    api_args:
      symbol: '$VIX'
      #symbol: 'VIX'    # 'symbol' is used to construct the URL to fetch the data
  # These work
  IBM:
    api: sc
    api_args:
      symbol: IBM
  AAPL:
    api: sc
    api_args:
      symbol: AAPL


  # Whysper API: This works. Just use it for testing.
  # Put this in between "sc" type feeds to force re-logging in
  #WHYSPER_1:
  #  api: whysper
  #  api_args:
  #    url: "https://whysper.io"


  # WTF ... As of 2022-01-07, this feed is not working properly
  # API docs: https://apps.newyorkfed.org/~/media/XML/Schemas/api_spec
  FED_Soma:
    api: fed
    api_args:
      symbol: "FED_Soma"
      productCode: "30"
      query: "details"
      holdingTypes: "bills,notesbonds,frn,tips,cmbs,agency%20debts"
      format: "csv"
  #
  #  # TODO: Somehow deal with the fact that this API is fragile.
  #  # It always seems to succeed if a year of data is pulled, but often fails if fewer days are pulled
  #  # FAIL
  #  #  ./pyalgofetcher.py -f FED_Soma -s 1990-11-01 -e 1990-12-31 -d /tmp
  #  # SUCCEED
  #  # ./pyalgofetcher.py -f FED_Soma -s 1990-01-01 -e 1991-01-01 -d /tmp


  # WTF ... as of 2022-01-05, this is not returning dates
  # API docs: https://pandas-datareader.readthedocs.io/en/latest/remote_data.html#yahoo-finance-data
  #
  #
  #VIX: # Seems to only have data from 2014-12-04 and 2018-01-31, and even then, some days are missing.
  #  api: pdr
  #  api_args:
  #    symbol: "VIX"
  #    source: "yahoo"
  #SPY:
  #  api: pdr
  #  api_args:
  #    symbol: "SPY"
  #    source: "yahoo"


# Do not put private information in this file!
# Copy this section into a file ./overrides.yaml and set the parameters there.
credentials:
  feed_api:
    whysper:
      username: username-override-me
      password: password-override-me
    sc:
      username: username-override-me
      password: password-override-me

